{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bab69029-fa85-4a7f-a969-adef33bfa802",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d875ca6",
   "metadata": {},
   "source": [
    "### Bangalore Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c6691fe-1aff-4c8e-8279-a811a7c17f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# Load your Excel file\n",
    "input_excel_path = 'C:\\\\Users\\\\Siva\\\\Capstone Projects\\\\Car Dheko\\\\Datasets\\\\bangalore_cars.xlsx'\n",
    "\n",
    "# Read the Excel file into a pandas DataFrame\n",
    "df = pd.read_excel(input_excel_path, engine='openpyxl')\n",
    "\n",
    "output_csv_path = 'C:\\\\Users\\\\Siva\\\\Capstone Projects\\\\Car Dheko\\\\Datasets\\\\bangalore_cars_Structured.csv'\n",
    "\n",
    "# Function to flatten the dictionary\n",
    "def flatten_dict(d, parent_key='', sep='_'):\n",
    "    items = []\n",
    "    for k, v in d.items():\n",
    "        new_key = f'{parent_key}{sep}{k}' if parent_key else k\n",
    "        if isinstance(v, dict):\n",
    "            items.extend(flatten_dict(v, new_key, sep=sep).items())\n",
    "        elif isinstance(v, list):\n",
    "            for i, item in enumerate(v):\n",
    "                if isinstance(item, dict):\n",
    "                    items.extend(flatten_dict(item, f'{new_key}_{i}', sep=sep).items())\n",
    "                else:\n",
    "                    items.append((f'{new_key}_{i}', item))\n",
    "        else:\n",
    "            items.append((new_key, v))\n",
    "    return dict(items)\n",
    "\n",
    "# Initialize empty DataFrames for each column\n",
    "structured_details_df = pd.DataFrame()\n",
    "structured_overview_df = pd.DataFrame()\n",
    "structured_features_df = pd.DataFrame()\n",
    "structured_specs_df = pd.DataFrame()\n",
    "structured_links_df = pd.DataFrame()\n",
    "\n",
    "# Process 'new_car_detail' column\n",
    "flattened_data = []\n",
    "for index, row in df.iterrows():\n",
    "    unstructured_data = row['new_car_detail']\n",
    "    unstructured_data = ast.literal_eval(unstructured_data)\n",
    "    flattened_row = flatten_dict(unstructured_data)\n",
    "    flattened_data.append(flattened_row)\n",
    "structured_details_df = pd.DataFrame(flattened_data)\n",
    "\n",
    "# Process 'new_car_overview' column\n",
    "flattened_data = []\n",
    "for index, row in df.iterrows():\n",
    "    unstructured_data = row['new_car_overview']\n",
    "    unstructured_data = ast.literal_eval(unstructured_data)\n",
    "    flattened_row = flatten_dict(unstructured_data)\n",
    "    flattened_data.append(flattened_row)\n",
    "structured_overview_df = pd.DataFrame(flattened_data)\n",
    "\n",
    "# Process 'new_car_feature' column\n",
    "flattened_data = []\n",
    "for index, row in df.iterrows():\n",
    "    unstructured_data = row['new_car_feature']\n",
    "    unstructured_data = ast.literal_eval(unstructured_data)\n",
    "    flattened_row = flatten_dict(unstructured_data)\n",
    "    flattened_data.append(flattened_row)\n",
    "structured_features_df = pd.DataFrame(flattened_data)\n",
    "\n",
    "# Process 'new_car_specs' column\n",
    "flattened_data = []\n",
    "for index, row in df.iterrows():\n",
    "    unstructured_data = row['new_car_specs']\n",
    "    unstructured_data = ast.literal_eval(unstructured_data)\n",
    "    flattened_row = flatten_dict(unstructured_data)\n",
    "    flattened_data.append(flattened_row)\n",
    "structured_specs_df = pd.DataFrame(flattened_data)\n",
    "\n",
    "# Process 'car_links' column (if not a nested structure, just copy as is)\n",
    "structured_links_df = df[['car_links']].copy()\n",
    "\n",
    "# Merge all structured DataFrames into one\n",
    "bangalore_cars_Structured = pd.concat([structured_details_df, structured_overview_df, structured_features_df, structured_specs_df, structured_links_df], axis=1)\n",
    "\n",
    "# Add the 'City' column\n",
    "# Assign the city name to all rows; you can change 'YourCityName' to the desired city name\n",
    "bangalore_cars_Structured['City'] = 'Bangalore'\n",
    "\n",
    "# Save the merged DataFrame to a CSV file\n",
    "bangalore_cars_Structured.to_csv(output_csv_path, index=False)\n",
    "\n",
    "# Display the merged DataFrame\n",
    "#print(bangalore_cars_Structured)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3600b6d",
   "metadata": {},
   "source": [
    "### Chennai Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "406bd6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# Load your Excel file\n",
    "input_excel_path = 'C:\\\\Users\\\\Siva\\\\Capstone Projects\\\\Car Dheko\\\\Datasets\\\\chennai_cars.xlsx'\n",
    "\n",
    "# Read the Excel file into a pandas DataFrame\n",
    "df = pd.read_excel(input_excel_path, engine='openpyxl')\n",
    "\n",
    "output_csv_path = 'C:\\\\Users\\\\Siva\\\\Capstone Projects\\\\Car Dheko\\\\Datasets\\\\chennai_cars_Structured.csv'\n",
    "\n",
    "# Function to flatten the dictionary\n",
    "def flatten_dict(d, parent_key='', sep='_'):\n",
    "    items = []\n",
    "    for k, v in d.items():\n",
    "        new_key = f'{parent_key}{sep}{k}' if parent_key else k\n",
    "        if isinstance(v, dict):\n",
    "            items.extend(flatten_dict(v, new_key, sep=sep).items())\n",
    "        elif isinstance(v, list):\n",
    "            for i, item in enumerate(v):\n",
    "                if isinstance(item, dict):\n",
    "                    items.extend(flatten_dict(item, f'{new_key}_{i}', sep=sep).items())\n",
    "                else:\n",
    "                    items.append((f'{new_key}_{i}', item))\n",
    "        else:\n",
    "            items.append((new_key, v))\n",
    "    return dict(items)\n",
    "\n",
    "# Initialize empty DataFrames for each column\n",
    "structured_details_df = pd.DataFrame()\n",
    "structured_overview_df = pd.DataFrame()\n",
    "structured_features_df = pd.DataFrame()\n",
    "structured_specs_df = pd.DataFrame()\n",
    "structured_links_df = pd.DataFrame()\n",
    "\n",
    "# Process 'new_car_detail' column\n",
    "flattened_data = []\n",
    "for index, row in df.iterrows():\n",
    "    unstructured_data = row['new_car_detail']\n",
    "    unstructured_data = ast.literal_eval(unstructured_data)\n",
    "    flattened_row = flatten_dict(unstructured_data)\n",
    "    flattened_data.append(flattened_row)\n",
    "structured_details_df = pd.DataFrame(flattened_data)\n",
    "\n",
    "# Process 'new_car_overview' column\n",
    "flattened_data = []\n",
    "for index, row in df.iterrows():\n",
    "    unstructured_data = row['new_car_overview']\n",
    "    unstructured_data = ast.literal_eval(unstructured_data)\n",
    "    flattened_row = flatten_dict(unstructured_data)\n",
    "    flattened_data.append(flattened_row)\n",
    "structured_overview_df = pd.DataFrame(flattened_data)\n",
    "\n",
    "# Process 'new_car_feature' column\n",
    "flattened_data = []\n",
    "for index, row in df.iterrows():\n",
    "    unstructured_data = row['new_car_feature']\n",
    "    unstructured_data = ast.literal_eval(unstructured_data)\n",
    "    flattened_row = flatten_dict(unstructured_data)\n",
    "    flattened_data.append(flattened_row)\n",
    "structured_features_df = pd.DataFrame(flattened_data)\n",
    "\n",
    "# Process 'new_car_specs' column\n",
    "flattened_data = []\n",
    "for index, row in df.iterrows():\n",
    "    unstructured_data = row['new_car_specs']\n",
    "    unstructured_data = ast.literal_eval(unstructured_data)\n",
    "    flattened_row = flatten_dict(unstructured_data)\n",
    "    flattened_data.append(flattened_row)\n",
    "structured_specs_df = pd.DataFrame(flattened_data)\n",
    "\n",
    "# Process 'car_links' column (if not a nested structure, just copy as is)\n",
    "structured_links_df = df[['car_links']].copy()\n",
    "\n",
    "# Merge all structured DataFrames into one\n",
    "chennai_cars_Structured = pd.concat([structured_details_df, structured_overview_df, structured_features_df, structured_specs_df, structured_links_df], axis=1)\n",
    "\n",
    "# Add the 'City' column\n",
    "# Assign the city name to all rows; you can change 'YourCityName' to the desired city name\n",
    "chennai_cars_Structured['City'] = 'Chennai'\n",
    "\n",
    "# Save the merged DataFrame to a CSV file\n",
    "chennai_cars_Structured.to_csv(output_csv_path, index=False)\n",
    "\n",
    "# Display the merged DataFrame\n",
    "#print(chennai_cars_Structured)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ba50a5",
   "metadata": {},
   "source": [
    "### Delhi Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90a5c393",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# Load your Excel file\n",
    "input_excel_path = 'C:\\\\Users\\\\Siva\\\\Capstone Projects\\\\Car Dheko\\\\Datasets\\\\delhi_cars.xlsx'\n",
    "\n",
    "# Read the Excel file into a pandas DataFrame\n",
    "df = pd.read_excel(input_excel_path, engine='openpyxl')\n",
    "\n",
    "output_csv_path = 'C:\\\\Users\\\\Siva\\\\Capstone Projects\\\\Car Dheko\\\\Datasets\\\\delhi_cars_Structured.csv'\n",
    "\n",
    "# Function to flatten the dictionary\n",
    "def flatten_dict(d, parent_key='', sep='_'):\n",
    "    items = []\n",
    "    for k, v in d.items():\n",
    "        new_key = f'{parent_key}{sep}{k}' if parent_key else k\n",
    "        if isinstance(v, dict):\n",
    "            items.extend(flatten_dict(v, new_key, sep=sep).items())\n",
    "        elif isinstance(v, list):\n",
    "            for i, item in enumerate(v):\n",
    "                if isinstance(item, dict):\n",
    "                    items.extend(flatten_dict(item, f'{new_key}_{i}', sep=sep).items())\n",
    "                else:\n",
    "                    items.append((f'{new_key}_{i}', item))\n",
    "        else:\n",
    "            items.append((new_key, v))\n",
    "    return dict(items)\n",
    "\n",
    "# Initialize empty DataFrames for each column\n",
    "structured_details_df = pd.DataFrame()\n",
    "structured_overview_df = pd.DataFrame()\n",
    "structured_features_df = pd.DataFrame()\n",
    "structured_specs_df = pd.DataFrame()\n",
    "structured_links_df = pd.DataFrame()\n",
    "\n",
    "# Process 'new_car_detail' column\n",
    "flattened_data = []\n",
    "for index, row in df.iterrows():\n",
    "    unstructured_data = row['new_car_detail']\n",
    "    unstructured_data = ast.literal_eval(unstructured_data)\n",
    "    flattened_row = flatten_dict(unstructured_data)\n",
    "    flattened_data.append(flattened_row)\n",
    "structured_details_df = pd.DataFrame(flattened_data)\n",
    "\n",
    "# Process 'new_car_overview' column\n",
    "flattened_data = []\n",
    "for index, row in df.iterrows():\n",
    "    unstructured_data = row['new_car_overview']\n",
    "    unstructured_data = ast.literal_eval(unstructured_data)\n",
    "    flattened_row = flatten_dict(unstructured_data)\n",
    "    flattened_data.append(flattened_row)\n",
    "structured_overview_df = pd.DataFrame(flattened_data)\n",
    "\n",
    "# Process 'new_car_feature' column\n",
    "flattened_data = []\n",
    "for index, row in df.iterrows():\n",
    "    unstructured_data = row['new_car_feature']\n",
    "    unstructured_data = ast.literal_eval(unstructured_data)\n",
    "    flattened_row = flatten_dict(unstructured_data)\n",
    "    flattened_data.append(flattened_row)\n",
    "structured_features_df = pd.DataFrame(flattened_data)\n",
    "\n",
    "# Process 'new_car_specs' column\n",
    "flattened_data = []\n",
    "for index, row in df.iterrows():\n",
    "    unstructured_data = row['new_car_specs']\n",
    "    unstructured_data = ast.literal_eval(unstructured_data)\n",
    "    flattened_row = flatten_dict(unstructured_data)\n",
    "    flattened_data.append(flattened_row)\n",
    "structured_specs_df = pd.DataFrame(flattened_data)\n",
    "\n",
    "# Process 'car_links' column (if not a nested structure, just copy as is)\n",
    "structured_links_df = df[['car_links']].copy()\n",
    "\n",
    "# Merge all structured DataFrames into one\n",
    "delhi_cars_Structured = pd.concat([structured_details_df, structured_overview_df, structured_features_df, structured_specs_df, structured_links_df], axis=1)\n",
    "\n",
    "# Add the 'City' column\n",
    "# Assign the city name to all rows; you can change 'YourCityName' to the desired city name\n",
    "delhi_cars_Structured['City'] = 'Delhi'\n",
    "\n",
    "# Save the merged DataFrame to a CSV file\n",
    "delhi_cars_Structured.to_csv(output_csv_path, index=False)\n",
    "\n",
    "# Display the merged DataFrame\n",
    "#print(delhi_cars_Structured)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b809a1c8",
   "metadata": {},
   "source": [
    "### Hyderabad Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be07e102",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# Load your Excel file\n",
    "input_excel_path = 'C:\\\\Users\\\\Siva\\\\Capstone Projects\\\\Car Dheko\\\\Datasets\\\\hyderabad_cars.xlsx'\n",
    "\n",
    "# Read the Excel file into a pandas DataFrame\n",
    "df = pd.read_excel(input_excel_path, engine='openpyxl')\n",
    "\n",
    "output_csv_path = 'C:\\\\Users\\\\Siva\\\\Capstone Projects\\\\Car Dheko\\\\Datasets\\\\hyderabad_cars_Structured.csv'\n",
    "\n",
    "# Function to flatten the dictionary\n",
    "def flatten_dict(d, parent_key='', sep='_'):\n",
    "    items = []\n",
    "    for k, v in d.items():\n",
    "        new_key = f'{parent_key}{sep}{k}' if parent_key else k\n",
    "        if isinstance(v, dict):\n",
    "            items.extend(flatten_dict(v, new_key, sep=sep).items())\n",
    "        elif isinstance(v, list):\n",
    "            for i, item in enumerate(v):\n",
    "                if isinstance(item, dict):\n",
    "                    items.extend(flatten_dict(item, f'{new_key}_{i}', sep=sep).items())\n",
    "                else:\n",
    "                    items.append((f'{new_key}_{i}', item))\n",
    "        else:\n",
    "            items.append((new_key, v))\n",
    "    return dict(items)\n",
    "\n",
    "# Initialize empty DataFrames for each column\n",
    "structured_details_df = pd.DataFrame()\n",
    "structured_overview_df = pd.DataFrame()\n",
    "structured_features_df = pd.DataFrame()\n",
    "structured_specs_df = pd.DataFrame()\n",
    "structured_links_df = pd.DataFrame()\n",
    "\n",
    "# Process 'new_car_detail' column\n",
    "flattened_data = []\n",
    "for index, row in df.iterrows():\n",
    "    unstructured_data = row['new_car_detail']\n",
    "    unstructured_data = ast.literal_eval(unstructured_data)\n",
    "    flattened_row = flatten_dict(unstructured_data)\n",
    "    flattened_data.append(flattened_row)\n",
    "structured_details_df = pd.DataFrame(flattened_data)\n",
    "\n",
    "# Process 'new_car_overview' column\n",
    "flattened_data = []\n",
    "for index, row in df.iterrows():\n",
    "    unstructured_data = row['new_car_overview']\n",
    "    unstructured_data = ast.literal_eval(unstructured_data)\n",
    "    flattened_row = flatten_dict(unstructured_data)\n",
    "    flattened_data.append(flattened_row)\n",
    "structured_overview_df = pd.DataFrame(flattened_data)\n",
    "\n",
    "# Process 'new_car_feature' column\n",
    "flattened_data = []\n",
    "for index, row in df.iterrows():\n",
    "    unstructured_data = row['new_car_feature']\n",
    "    unstructured_data = ast.literal_eval(unstructured_data)\n",
    "    flattened_row = flatten_dict(unstructured_data)\n",
    "    flattened_data.append(flattened_row)\n",
    "structured_features_df = pd.DataFrame(flattened_data)\n",
    "\n",
    "# Process 'new_car_specs' column\n",
    "flattened_data = []\n",
    "for index, row in df.iterrows():\n",
    "    unstructured_data = row['new_car_specs']\n",
    "    unstructured_data = ast.literal_eval(unstructured_data)\n",
    "    flattened_row = flatten_dict(unstructured_data)\n",
    "    flattened_data.append(flattened_row)\n",
    "structured_specs_df = pd.DataFrame(flattened_data)\n",
    "\n",
    "# Process 'car_links' column (if not a nested structure, just copy as is)\n",
    "structured_links_df = df[['car_links']].copy()\n",
    "\n",
    "# Merge all structured DataFrames into one\n",
    "hyderabad_cars_Structured = pd.concat([structured_details_df, structured_overview_df, structured_features_df, structured_specs_df, structured_links_df], axis=1)\n",
    "\n",
    "# Add the 'City' column\n",
    "# Assign the city name to all rows; you can change 'YourCityName' to the desired city name\n",
    "hyderabad_cars_Structured['City'] = 'Hyderabad'\n",
    "\n",
    "# Save the merged DataFrame to a CSV file\n",
    "hyderabad_cars_Structured.to_csv(output_csv_path, index=False)\n",
    "\n",
    "# Display the merged DataFrame\n",
    "#print(hyderabad_cars_Structured)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee3e6ef",
   "metadata": {},
   "source": [
    "### Jaipur Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ad876f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# Load your Excel file\n",
    "input_excel_path = 'C:\\\\Users\\\\Siva\\\\Capstone Projects\\\\Car Dheko\\\\Datasets\\\\jaipur_cars.xlsx'\n",
    "\n",
    "# Read the Excel file into a pandas DataFrame\n",
    "df = pd.read_excel(input_excel_path, engine='openpyxl')\n",
    "\n",
    "output_csv_path = 'C:\\\\Users\\\\Siva\\\\Capstone Projects\\\\Car Dheko\\\\Datasets\\\\jaipur_cars_Structured.csv'\n",
    "\n",
    "# Function to flatten the dictionary\n",
    "def flatten_dict(d, parent_key='', sep='_'):\n",
    "    items = []\n",
    "    for k, v in d.items():\n",
    "        new_key = f'{parent_key}{sep}{k}' if parent_key else k\n",
    "        if isinstance(v, dict):\n",
    "            items.extend(flatten_dict(v, new_key, sep=sep).items())\n",
    "        elif isinstance(v, list):\n",
    "            for i, item in enumerate(v):\n",
    "                if isinstance(item, dict):\n",
    "                    items.extend(flatten_dict(item, f'{new_key}_{i}', sep=sep).items())\n",
    "                else:\n",
    "                    items.append((f'{new_key}_{i}', item))\n",
    "        else:\n",
    "            items.append((new_key, v))\n",
    "    return dict(items)\n",
    "\n",
    "# Initialize empty DataFrames for each column\n",
    "structured_details_df = pd.DataFrame()\n",
    "structured_overview_df = pd.DataFrame()\n",
    "structured_features_df = pd.DataFrame()\n",
    "structured_specs_df = pd.DataFrame()\n",
    "structured_links_df = pd.DataFrame()\n",
    "\n",
    "# Process 'new_car_detail' column\n",
    "flattened_data = []\n",
    "for index, row in df.iterrows():\n",
    "    unstructured_data = row['new_car_detail']\n",
    "    unstructured_data = ast.literal_eval(unstructured_data)\n",
    "    flattened_row = flatten_dict(unstructured_data)\n",
    "    flattened_data.append(flattened_row)\n",
    "structured_details_df = pd.DataFrame(flattened_data)\n",
    "\n",
    "# Process 'new_car_overview' column\n",
    "flattened_data = []\n",
    "for index, row in df.iterrows():\n",
    "    unstructured_data = row['new_car_overview']\n",
    "    unstructured_data = ast.literal_eval(unstructured_data)\n",
    "    flattened_row = flatten_dict(unstructured_data)\n",
    "    flattened_data.append(flattened_row)\n",
    "structured_overview_df = pd.DataFrame(flattened_data)\n",
    "\n",
    "# Process 'new_car_feature' column\n",
    "flattened_data = []\n",
    "for index, row in df.iterrows():\n",
    "    unstructured_data = row['new_car_feature']\n",
    "    unstructured_data = ast.literal_eval(unstructured_data)\n",
    "    flattened_row = flatten_dict(unstructured_data)\n",
    "    flattened_data.append(flattened_row)\n",
    "structured_features_df = pd.DataFrame(flattened_data)\n",
    "\n",
    "# Process 'new_car_specs' column\n",
    "flattened_data = []\n",
    "for index, row in df.iterrows():\n",
    "    unstructured_data = row['new_car_specs']\n",
    "    unstructured_data = ast.literal_eval(unstructured_data)\n",
    "    flattened_row = flatten_dict(unstructured_data)\n",
    "    flattened_data.append(flattened_row)\n",
    "structured_specs_df = pd.DataFrame(flattened_data)\n",
    "\n",
    "# Process 'car_links' column (if not a nested structure, just copy as is)\n",
    "structured_links_df = df[['car_links']].copy()\n",
    "\n",
    "# Merge all structured DataFrames into one\n",
    "jaipur_cars_Structured = pd.concat([structured_details_df, structured_overview_df, structured_features_df, structured_specs_df, structured_links_df], axis=1)\n",
    "\n",
    "# Add the 'City' column\n",
    "# Assign the city name to all rows; you can change 'YourCityName' to the desired city name\n",
    "jaipur_cars_Structured['City'] = 'Jaipur'\n",
    "\n",
    "# Save the merged DataFrame to a CSV file\n",
    "jaipur_cars_Structured.to_csv(output_csv_path, index=False)\n",
    "\n",
    "# Display the merged DataFrame\n",
    "#print(jaipur_cars_Structured)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bce85e",
   "metadata": {},
   "source": [
    "### Kolkata Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1a7bfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# Load your Excel file\n",
    "input_excel_path = 'C:\\\\Users\\\\Siva\\\\Capstone Projects\\\\Car Dheko\\\\Datasets\\\\kolkata_cars.xlsx'\n",
    "\n",
    "# Read the Excel file into a pandas DataFrame\n",
    "df = pd.read_excel(input_excel_path, engine='openpyxl')\n",
    "\n",
    "output_csv_path = 'C:\\\\Users\\\\Siva\\\\Capstone Projects\\\\Car Dheko\\\\Datasets\\\\kolkata_cars_Structured.csv'\n",
    "\n",
    "# Function to flatten the dictionary\n",
    "def flatten_dict(d, parent_key='', sep='_'):\n",
    "    items = []\n",
    "    for k, v in d.items():\n",
    "        new_key = f'{parent_key}{sep}{k}' if parent_key else k\n",
    "        if isinstance(v, dict):\n",
    "            items.extend(flatten_dict(v, new_key, sep=sep).items())\n",
    "        elif isinstance(v, list):\n",
    "            for i, item in enumerate(v):\n",
    "                if isinstance(item, dict):\n",
    "                    items.extend(flatten_dict(item, f'{new_key}_{i}', sep=sep).items())\n",
    "                else:\n",
    "                    items.append((f'{new_key}_{i}', item))\n",
    "        else:\n",
    "            items.append((new_key, v))\n",
    "    return dict(items)\n",
    "\n",
    "# Initialize empty DataFrames for each column\n",
    "structured_details_df = pd.DataFrame()\n",
    "structured_overview_df = pd.DataFrame()\n",
    "structured_features_df = pd.DataFrame()\n",
    "structured_specs_df = pd.DataFrame()\n",
    "structured_links_df = pd.DataFrame()\n",
    "\n",
    "# Process 'new_car_detail' column\n",
    "flattened_data = []\n",
    "for index, row in df.iterrows():\n",
    "    unstructured_data = row['new_car_detail']\n",
    "    unstructured_data = ast.literal_eval(unstructured_data)\n",
    "    flattened_row = flatten_dict(unstructured_data)\n",
    "    flattened_data.append(flattened_row)\n",
    "structured_details_df = pd.DataFrame(flattened_data)\n",
    "\n",
    "# Process 'new_car_overview' column\n",
    "flattened_data = []\n",
    "for index, row in df.iterrows():\n",
    "    unstructured_data = row['new_car_overview']\n",
    "    unstructured_data = ast.literal_eval(unstructured_data)\n",
    "    flattened_row = flatten_dict(unstructured_data)\n",
    "    flattened_data.append(flattened_row)\n",
    "structured_overview_df = pd.DataFrame(flattened_data)\n",
    "\n",
    "# Process 'new_car_feature' column\n",
    "flattened_data = []\n",
    "for index, row in df.iterrows():\n",
    "    unstructured_data = row['new_car_feature']\n",
    "    unstructured_data = ast.literal_eval(unstructured_data)\n",
    "    flattened_row = flatten_dict(unstructured_data)\n",
    "    flattened_data.append(flattened_row)\n",
    "structured_features_df = pd.DataFrame(flattened_data)\n",
    "\n",
    "# Process 'new_car_specs' column\n",
    "flattened_data = []\n",
    "for index, row in df.iterrows():\n",
    "    unstructured_data = row['new_car_specs']\n",
    "    unstructured_data = ast.literal_eval(unstructured_data)\n",
    "    flattened_row = flatten_dict(unstructured_data)\n",
    "    flattened_data.append(flattened_row)\n",
    "structured_specs_df = pd.DataFrame(flattened_data)\n",
    "\n",
    "# Process 'car_links' column (if not a nested structure, just copy as is)\n",
    "structured_links_df = df[['car_links']].copy()\n",
    "\n",
    "# Merge all structured DataFrames into one\n",
    "kolkata_cars_Structured = pd.concat([structured_details_df, structured_overview_df, structured_features_df, structured_specs_df, structured_links_df], axis=1)\n",
    "\n",
    "# Add the 'City' column\n",
    "# Assign the city name to all rows; you can change 'YourCityName' to the desired city name\n",
    "kolkata_cars_Structured['City'] = 'Kolkata'\n",
    "\n",
    "# Save the merged DataFrame to a CSV file\n",
    "kolkata_cars_Structured.to_csv(output_csv_path, index=False)\n",
    "\n",
    "# Display the merged DataFrame\n",
    "#print(kolkata_cars_Structured)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d28a1e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All datasets concatenated and saved to C:\\Users\\Siva\\Capstone Projects\\Car Dheko\\Datasets\\all_datasets_Structured.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# List of file paths for each city's dataset\n",
    "file_paths = [\n",
    "    'C:\\\\Users\\\\Siva\\\\Capstone Projects\\\\Car Dheko\\\\Datasets\\\\bangalore_cars_Structured.csv',\n",
    "    'C:\\\\Users\\\\Siva\\\\Capstone Projects\\\\Car Dheko\\\\Datasets\\\\chennai_cars_Structured.csv',\n",
    "    'C:\\\\Users\\\\Siva\\\\Capstone Projects\\\\Car Dheko\\\\Datasets\\\\delhi_cars_Structured.csv',\n",
    "    'C:\\\\Users\\\\Siva\\\\Capstone Projects\\\\Car Dheko\\\\Datasets\\\\hyderabad_cars_Structured.csv',\n",
    "    'C:\\\\Users\\\\Siva\\\\Capstone Projects\\\\Car Dheko\\\\Datasets\\\\jaipur_cars_Structured.csv',\n",
    "    'C:\\\\Users\\\\Siva\\\\Capstone Projects\\\\Car Dheko\\\\Datasets\\\\kolkata_cars_Structured.csv'\n",
    "]\n",
    "\n",
    "# List to store the individual DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Loop through each file path and read the CSV file into a DataFrame\n",
    "for file_path in file_paths:\n",
    "    df = pd.read_csv(file_path)\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Save the combined DataFrame to the specified path\n",
    "output_path = 'C:\\\\Users\\\\Siva\\\\Capstone Projects\\\\Car Dheko\\\\Datasets\\\\all_datasets_Structured.csv'\n",
    "combined_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"All datasets concatenated and saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb41d0d9-5388-45aa-bafa-40ca520f1824",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
